{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#PATH PROCESS\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# image processing\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Neural Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img_ex = '../input/shanghaitech-with-people-density-map/ShanghaiTech/part_B/train_data/images/IMG_6.jpg'\n",
    "image_ex = cv2.cvtColor(cv2.imread(path_img_ex),cv2.COLOR_BGR2RGB)\n",
    "figure = plt.figure(figsize=(5,5))\n",
    "plt.imshow(image_ex)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gt_ex = \"../input/shanghaitech-with-people-density-map/ShanghaiTech/part_B/train_data/ground-truth/GT_IMG_6.mat\"\n",
    "gt_ex = loadmat(path_gt_ex)\n",
    "print('type: ', type(gt_ex))\n",
    "print(gt_ex.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt_ex.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_coor_ex = gt_ex.get('image_info')[0][0][0][0][0]\n",
    "print('Shape of coordinates: ', gt_coor_ex.shape)\n",
    "#print(gt_coor_ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(5,5))\n",
    "\n",
    "for x_cor, y_cor in gt_coor_ex:\n",
    "    cv2.drawMarker(image_ex, (int(x_cor), int(y_cor)),(255, 0, 0),thickness=3)\n",
    "\n",
    "plt.imshow(image_ex)\n",
    "plt.title(\"Image and Coordinate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_density_map_gaussian(image, coords, sigma=5):\n",
    "    img_zeros = np.zeros((image.shape[:2]), dtype=np.float32)\n",
    "    for x_cor, y_cor in coords:\n",
    "        img_zeros[int(y_cor), int(x_cor)] = 1\n",
    "\n",
    "    density_map = gaussian_filter(img_zeros,sigma=sigma,truncate=5*5)\n",
    "\n",
    "    return density_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_map_ex = gen_density_map_gaussian(image_ex, gt_coor_ex, 5)\n",
    "\n",
    "figure = plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "image_ex = torch.tensor(image_ex/255, dtype=torch.float)\n",
    "plt.xlabel(image_ex.shape)\n",
    "plt.title('GT: '+str(gt_coor_ex.shape[0]))\n",
    "plt.imshow(image_ex)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.xlabel(density_map_ex.shape)\n",
    "plt.title('DM: '+str(np.sum(density_map_ex)))\n",
    "plt.imshow(density_map_ex, cmap=\"jet\")\n",
    "\n",
    "print('max1 : ', image_ex.max())\n",
    "print('max2 : ', density_map_ex.max())\n",
    "print('min1 : ', image_ex.min())\n",
    "print('min2 : ', density_map_ex.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Dataset):\n",
    "    def __init__(self, root_dir, gt_downsample=4, shuffle=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.gt_downsample = gt_downsample\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "\n",
    "        self.img_names = [filename for filename in os.listdir(os.path.join(root_dir, 'images')) if filename.endswith('.jpg')]\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.img_names)\n",
    "\n",
    "        self.n_people = {}\n",
    "        self.DMs = {}\n",
    "        for image_filename in self.img_names:\n",
    "            img_path = os.path.join(root_dir, 'images', image_filename)\n",
    "            GT_filename = 'GT_' + image_filename.split('.')[0] + '.mat'\n",
    "            path_GT = os.path.join(root_dir, 'ground-truth', GT_filename)\n",
    "            GT = loadmat(path_GT).get('image_info')[0][0][0][0][0]\n",
    "            img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "            self.DMs[img_path] = gen_density_map_gaussian(img, GT, 5)\n",
    "            self.n_people[img_path] = GT.shape[0]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, 'images', self.img_names[index])  # Include the directory path\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        gt_density_map = self.DMs[img_path]\n",
    "        gt_n_people = self.n_people[img_path]\n",
    "\n",
    "        if len(img.shape) == 2: # expand grayscale image to three channel.\n",
    "            img = img[:, :, np.newaxis]\n",
    "            img = np.concatenate((img, img, img), 2)\n",
    "\n",
    "        # downsample\n",
    "        ds_rows = int(img.shape[0] // self.gt_downsample)\n",
    "        ds_cols = int(img.shape[1] // self.gt_downsample)\n",
    "        img = cv2.resize(img, (ds_cols*self.gt_downsample, ds_rows*self.gt_downsample))\n",
    "        gt_density_map = cv2.resize(gt_density_map, (ds_cols, ds_rows))\n",
    "        gt_density_map = gt_density_map[np.newaxis, :, :] * self.gt_downsample * self.gt_downsample\n",
    "\n",
    "        img = img.transpose((2,0,1)) # convert to order (channel, rows, cols)\n",
    "        img_tensor = torch.tensor(img/255, dtype=torch.float)\n",
    "        dm_tensor = torch.tensor(gt_density_map, dtype=torch.float)\n",
    "\n",
    "        return img_tensor, dm_tensor, gt_n_people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../input/shanghaitech-with-people-density-map/ShanghaiTech/part_B/test_data/\"\n",
    "dataset = DataLoader(root_dir, gt_downsample=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (img, gt_dmap, n_people) in enumerate(dataset):\n",
    "  plt.figure(figsize=(10, 5))\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.xlabel(img.shape)\n",
    "  plt.title('GT: ' + str(n_people))\n",
    "  plt.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.xlabel(gt_dmap.shape)\n",
    "  plt.title('DM: ' + str(np.sum(gt_dmap.numpy())))\n",
    "  plt.imshow(gt_dmap.permute(1, 2, 0), cmap=\"jet\")\n",
    "  plt.show()\n",
    "\n",
    "  if i > 0:\n",
    "    #print('type of img: ', type(img))\n",
    "    #print('type of dmap: ', type(gt_dmap))\n",
    "    #print('shape of img: ', img.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MC_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.column1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 9, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(8, 16, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 8, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.column2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 10, 7,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(10, 20, 5,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(20, 40, 5,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(40, 20, 5,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(20, 10, 5,padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.column3 = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 5, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(12, 24, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(24, 48, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(48, 24, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(24, 12, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Conv2d(30, 1, 1, padding=0),\n",
    "            #nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,img_tensor):\n",
    "        x1 = self.column1(img_tensor)\n",
    "        x2 = self.column2(img_tensor)\n",
    "        x3 = self.column3(img_tensor)\n",
    "        x = torch.cat((x1, x2, x3),1)\n",
    "        x = self.fusion_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=torch.rand((1,3,768,1024),dtype=torch.float)\n",
    "mcnn=MC_CNN()\n",
    "out_dmap=mcnn(img)\n",
    "print(out_dmap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_root_dir = \"../input/shanghaitech-with-people-density-map/ShanghaiTech/part_B/train_data/\"\n",
    "init_training_set = DataLoader(train_root_dir, gt_downsample=4, shuffle=True)\n",
    "\n",
    "# split part of the training set as validation set\n",
    "train_size = int(0.9 * len(init_training_set))\n",
    "val_size = len(init_training_set) - train_size\n",
    "\n",
    "train_indices = list(range(train_size))\n",
    "val_indices = list(range(train_size, len(init_training_set)))\n",
    "train_dataset = torch.utils.data.dataset.Subset(init_training_set, train_indices)\n",
    "val_dataset = torch.utils.data.dataset.Subset(init_training_set, val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_root_dir = \"../input/shanghaitech-with-people-density-map/ShanghaiTech/part_B/test_data\"\n",
    "test_set = DataLoader(test_root_dir, gt_downsample=4, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Number of batches in train_loader:\", len(train_loader))\n",
    "print(\"Number of batches in val_loader:\", len(val_loader))\n",
    "print(\"Number of batches in test_loader:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corresponding_pairs(batch1, batch2, plot_map='jet'):\n",
    "    num_images = batch1.shape[0] # can change to 4 if for entire data set\n",
    "\n",
    "    fig, axes = plt.subplots(int(np.ceil(num_images/2)), 4)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        axes[int(i/4)*2, i%4].imshow(batch1[i].permute(1, 2, 0))\n",
    "        axes[int(i/4)*2, i%4].axis('off')\n",
    "\n",
    "        axes[int(i/4)*2+1, i%4].imshow(batch2[i].squeeze().detach().numpy(), cmap=plot_map)\n",
    "        axes[int(i/4)*2+1, i%4].axis('off')\n",
    "        axes[int(i/4)*2+1, i%4].set_title('DM: ' + str(np.sum(batch2[i].detach().numpy())))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "ex_images, ex_dmaps, ex_n_people = next(dataiter)\n",
    "\n",
    "\n",
    "# Show images and density map\n",
    "plot_corresponding_pairs(ex_images, ex_dmaps)\n",
    "\n",
    "# Print Ground truth number of people\n",
    "print(' '.join('%5s' % ex_n_people[j].item() for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, weight_dmap=0.8, weight_sum_gt=0.2):\n",
    "        super().__init__()\n",
    "        self.weight_dmap = weight_dmap\n",
    "        self.weight_sum_gt = weight_sum_gt\n",
    "        self.img_loss = nn.MSELoss()\n",
    "        self.gt_loss_mse = nn.MSELoss()\n",
    "        self.gt_loss_mae = nn.L1Loss()\n",
    "\n",
    "    def forward(self, logits, batch_dmap, batch_gts):\n",
    "        batch_gts = batch_gts.float()\n",
    "        img_loss = self.img_loss(logits, batch_dmap)\n",
    "        gt_loss_mae = self.gt_loss_mae(torch.squeeze(logits.sum(dim=(2,3))), batch_gts)\n",
    "        gt_loss_mse = self.gt_loss_mse(torch.squeeze(logits.sum(dim=(2,3))), batch_gts)\n",
    "        \n",
    "        #print('logits : ', torch.squeeze(logits.sum(dim=(2,3))))\n",
    "        #print('gts    : ', batch_gts)\n",
    "        #print('MAE:  ', gt_loss_mae)\n",
    "        \n",
    "        combined_loss = self.weight_dmap * img_loss + self.weight_sum_gt * gt_loss_mae\n",
    "        return combined_loss, gt_loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "#train_losses = np.zeros(num_epochs)\n",
    "#val_losses = np.zeros(num_epochs)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_mae_losses = []\n",
    "val_mae_losses = []\n",
    "\n",
    "\n",
    "model = MC_CNN().to(device)\n",
    "criterion = CombinedLoss(0.8, 0.2)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "best_val_loss = np.inf\n",
    "best_nr_epoch = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "\n",
    "    # training phase\n",
    "    tr_loss_acc = 0.0\n",
    "    tr_loss_mae_acc = 0.0\n",
    "\n",
    "    for batch_img, batch_dmap, batch_gts in train_loader:\n",
    "        # Put data on device\n",
    "        batch_img, batch_dmap, batch_gts = batch_img.to(device), batch_dmap.to(device), batch_gts.to(device)\n",
    "        # Predict and get loss\n",
    "        logits = model(batch_img)\n",
    "        loss, mae_loss = criterion(logits, batch_dmap, batch_gts)\n",
    "        # Update model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Keep running statistics\n",
    "        tr_loss_acc += loss.item()\n",
    "        tr_loss_mae_acc += mae_loss.item()\n",
    "        #print('acc mae = ', tr_loss_mae_acc)\n",
    "        \n",
    "\n",
    "    tr_loss = tr_loss_acc / len(train_loader.dataset) # change to this when entire dataset\n",
    "    tr_mae = tr_loss_mae_acc / len(train_loader.dataset)\n",
    "    print('>> TRAIN: Epoch {} | tr_loss:  {:.6f}'.format(epoch, tr_loss))\n",
    "    print('>> TRAIN: Epoch {} | mae:      {:.6f}'.format(epoch, tr_mae))\n",
    "    \n",
    "    # Get validation results\n",
    "    with torch.inference_mode():\n",
    "        val_loss_acc = 0.0\n",
    "        val_loss_mae_acc = 0.0\n",
    "        \n",
    "        for batch_img_val, batch_dmap_val, batch_gts_val in val_loader:\n",
    "            # Put data on device\n",
    "            batch_img_val, batch_dmap_val, batch_gts_val = batch_img_val.to(device), batch_dmap_val.to(device), batch_gts_val.to(device)\n",
    "\n",
    "            # Predict and get loss\n",
    "            logits = model(batch_img_val)\n",
    "            loss, mae_loss = criterion(logits, batch_dmap_val, batch_gts_val)\n",
    "\n",
    "            # Keep running statistics\n",
    "            val_loss_acc += loss.item()\n",
    "            val_loss_mae_acc += mae_loss.item()\n",
    "\n",
    "    val_loss = val_loss_acc / len(val_loader.dataset)\n",
    "    val_mae = val_loss_mae_acc / len(val_loader.dataset)\n",
    "    print('>> VAL:   Epoch {} | val_loss: {:.6f}'.format(epoch, val_loss))\n",
    "    print('>> VAL:   Epoch {} | mae:      {:.6f}'.format(epoch, val_mae))\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_nr_epoch = epoch\n",
    "        torch.save(model.state_dict(), './crowd_counting.pth')\n",
    "\n",
    "\n",
    "    train_losses.append(tr_loss)\n",
    "    train_mae_losses.append(tr_mae)\n",
    "    val_losses.append(val_loss)\n",
    "    val_mae_losses.append(val_mae)\n",
    "    \n",
    "print('best training MAE: ', train_mae_losses[best_nr_epoch])  \n",
    "print('best val MAE:      ', val_mae_losses[best_nr_epoch])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Weighted')\n",
    "plt.plot(val_losses, label='Validation Weighted')\n",
    "plt.title('Results')\n",
    "plt.ylabel('Weight Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_mae_losses, label='Training MAE')\n",
    "plt.plot(val_mae_losses, label='Validation MAE')\n",
    "plt.title('Results')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MC_CNN().to(device)\n",
    "best_model.load_state_dict(torch.load('./crowd_counting.pth'))\n",
    "# Get some random validation images\n",
    "dataiter = iter(val_loader)\n",
    "ex_images, _, ex_gts  = next(dataiter)\n",
    "\n",
    "\n",
    "# Show images and density map\n",
    "\n",
    "pred_dms = best_model(ex_images.to(device))\n",
    "plot_corresponding_pairs(ex_images.cpu(), pred_dms.cpu(), 'twilight')\n",
    "\n",
    "# Print labels\n",
    "print(' '.join('%5s' % ex_gts[j].item() for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MC_CNN().to(device)\n",
    "best_model.load_state_dict(torch.load('./crowd_counting.pth'))\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "test_loss_acc = 0.0\n",
    "with torch.inference_mode():\n",
    "    for batch_img, batch_dmap, batch_gts in test_loader:\n",
    "        batch_img, batch_dmap, batch_gts = batch_img.to(device), batch_dmap.to(device), batch_gts.to(device)\n",
    "\n",
    "        logits = best_model(batch_img)\n",
    "        loss = criterion(torch.squeeze(logits.sum(dim=(2,3))), batch_gts)\n",
    "\n",
    "        # Keep running statistics\n",
    "        test_loss_acc += loss.item()\n",
    "\n",
    "\n",
    "# Print results\n",
    "print('TEST:  test_MAE: {:.3f}'.format(test_loss_acc / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some random validation images\n",
    "dataiter = iter(test_loader)\n",
    "ex_images, _, ex_gts  = next(dataiter)\n",
    "\n",
    "\n",
    "# Show images and density map\n",
    "\n",
    "pred_dms = best_model(ex_images.to(device))\n",
    "plot_corresponding_pairs(ex_images.cpu(), pred_dms.cpu(), 'twilight')\n",
    "\n",
    "# Print labels\n",
    "print(' '.join('%5s' % ex_gts[j].item() for j in range(batch_size)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
